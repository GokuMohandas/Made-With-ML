{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "13_Recurrent_Neural_Networks",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "bOChJSNXtC9g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Recurrent Neural Networks"
      ]
    },
    {
      "metadata": {
        "id": "OLIxEDq6VhvZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/logo.png\" width=150>\n",
        "\n",
        "When working with sequential data (time-series, sentences, etc.) the order of the inputs is crucial for the task at hand. Recurrent neural networks (RNNs) process sequential data by accounting for the current input and also what has been learned from previous inputs. In this notebook, we'll learn how to create and train RNNs on sequential data.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/rnn.png\" width=550>\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "VoMq0eFRvugb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Overview"
      ]
    },
    {
      "metadata": {
        "id": "qWro5T5qTJJL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* **Objective:**  Process sequential data by accounting for the currend input and also what has been learned from previous inputs.\n",
        "* **Advantages:** \n",
        "    * Account for order and previous inputs in a meaningful way.\n",
        "    * Conditioned generation for generating sequences.\n",
        "* **Disadvantages:** \n",
        "    * Each time step's prediction depends on the previous prediction so it's difficult to parallelize RNN operations. \n",
        "    * Processing long sequences can yield memory and computation issues.\n",
        "    * Interpretability is difficult but there are few [techniques](https://arxiv.org/abs/1506.02078) that use the activations from RNNs to see what parts of the inputs are processed. \n",
        "* **Miscellaneous:** \n",
        "    * Architectural tweaks to make RNNs faster and interpretable is an ongoing area of research."
      ]
    },
    {
      "metadata": {
        "id": "rsHeBbehrKzl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/rnn2.png\" width=650>\n",
        "\n",
        "RNN forward pass for a single time step $X_t$:\n",
        "\n",
        "$h_t = tanh(W_{hh}h_{t-1} + W_{xh}X_t+b_h)$\n",
        "\n",
        "$y_t = W_{hy}h_t + b_y $\n",
        "\n",
        "$ P(y) = softmax(y_t) = \\frac{e^y}{\\sum e^y} $\n",
        "\n",
        "*where*:\n",
        "* $X_t$ = input at time step t | $\\in \\mathbb{R}^{NXE}$ ($N$ is the batch size, $E$ is the embedding dim)\n",
        "* $W_{hh}$ = hidden units weights| $\\in \\mathbb{R}^{HXH}$ ($H$ is the hidden dim)\n",
        "* $h_{t-1}$ = previous timestep's hidden state $\\in \\mathbb{R}^{NXH}$\n",
        "* $W_{xh}$ = input weights| $\\in \\mathbb{R}^{EXH}$\n",
        "* $b_h$ = hidden units bias $\\in \\mathbb{R}^{HX1}$\n",
        "* $W_{hy}$ = output weights| $\\in \\mathbb{R}^{HXC}$ ($C$ is the number of classes)\n",
        "* $b_y$ = output bias $\\in \\mathbb{R}^{CX1}$\n",
        "\n",
        "You repeat this for every time step's input ($X_{t+1}, X_{t+2}, ..., X_{N})$ to the get the predicted outputs at each time step.\n",
        "\n",
        "**Note**: At the first time step, the previous hidden state $h_{t-1}$ can either be a zero vector (unconditioned) or initialize (conditioned). More on this in the subsequent notebooks on RNNs."
      ]
    },
    {
      "metadata": {
        "id": "dIXlGMExJD6w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's see what the forward pass looks like with an RNN for a synthetic task such as processing reviews (a sequence of words) to predict the sentiment at the end of processing the review."
      ]
    },
    {
      "metadata": {
        "id": "RcWE5cw0_cKA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loading PyTorch library\n",
        "!pip3 install http://download.pytorch.org/whl/cpu/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o6eEK1wM_dXG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qi9hIEV6COLF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 5\n",
        "seq_size = 10 # max length per input (masking will be used for sequences that aren't this max length)\n",
        "x_lengths = [8, 5, 4, 10, 5] # lengths of each input sequence\n",
        "embedding_dim = 100\n",
        "hidden_dim = 256\n",
        "output_dim = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bLEzfxjhB94C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "98e07399-76ba-4f31-a68a-1112c4612335"
      },
      "cell_type": "code",
      "source": [
        "# Initialize synthetic inputs\n",
        "x_in = torch.randn(batch_size, seq_size, embedding_dim)\n",
        "x_lengths = torch.tensor(x_lengths)\n",
        "print (x_in.size())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 10, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dr6oLqtXB98N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6ca85b1-e241-434d-f147-bf0a14362bcc"
      },
      "cell_type": "code",
      "source": [
        "# Initialize hidden state\n",
        "hidden_t = torch.zeros((batch_size, hidden_dim))\n",
        "print (hidden_t.size())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ryZMOLLgB9-v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f89be56c-a0ce-4c9b-a974-bcf5bf5cacf5"
      },
      "cell_type": "code",
      "source": [
        "# Initialize RNN cell\n",
        "rnn_cell = nn.RNNCell(embedding_dim, hidden_dim)\n",
        "print (rnn_cell)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNNCell(100, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rlbZ7ujxExXb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff779bc2-3d5e-48a1-d4a4-3b61221a72f1"
      },
      "cell_type": "code",
      "source": [
        "# Forward pass through RNN\n",
        "x_in = x_in.permute(1, 0, 2) # RNN needs batch_size to be at dim 1\n",
        "\n",
        "# Loop through the inputs time steps\n",
        "hiddens = []\n",
        "for t in range(seq_size):\n",
        "    hidden_t = rnn_cell(x_in[t], hidden_t)\n",
        "    hiddens.append(hidden_t)\n",
        "hiddens = torch.stack(hiddens)\n",
        "hiddens = hiddens.permute(1, 0, 2) # bring batch_size back to dim 0\n",
        "print (hiddens.size())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 10, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3TTL-jmg-MHa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7cfc12cf-0b7e-4a09-8067-bd1f6e1d5f09"
      },
      "cell_type": "code",
      "source": [
        "# We also could've used a more abstracted layer\n",
        "x_in = torch.randn(batch_size, seq_size, embedding_dim)\n",
        "rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
        "out, h_n = rnn(x_in) #h_n is the last hidden state\n",
        "print (\"out: \", out.size())\n",
        "print (\"h_n: \", h_n.size())"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "out:  torch.Size([5, 10, 256])\n",
            "h_n:  torch.Size([1, 5, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iAsyRNnbHwcT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gather_last_relevant_hidden(hiddens, x_lengths):\n",
        "    x_lengths = x_lengths.long().detach().cpu().numpy() - 1\n",
        "    out = []\n",
        "    for batch_index, column_index in enumerate(x_lengths):\n",
        "        out.append(hiddens[batch_index, column_index])\n",
        "    return torch.stack(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PVhp1KLqHqpA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a68eab42-6009-41c6-e215-8229c3772898"
      },
      "cell_type": "code",
      "source": [
        "# Gather the last relevant hidden state\n",
        "z = gather_last_relevant_hidden(hiddens, x_lengths)\n",
        "print (z.size())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yGk_iZ5cITZl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a25751f7-1787-4e12-9995-6beeec5f4099"
      },
      "cell_type": "code",
      "source": [
        "# Forward pass through FC layer\n",
        "fc1 = nn.Linear(hidden_dim, output_dim)\n",
        "y_pred = fc1(z)\n",
        "y_pred = F.softmax(y_pred, dim=1)\n",
        "print (y_pred.size())\n",
        "print (y_pred)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 4])\n",
            "tensor([[0.2951, 0.2300, 0.2032, 0.2716],\n",
            "        [0.2267, 0.2811, 0.2468, 0.2454],\n",
            "        [0.1707, 0.2743, 0.2568, 0.2981],\n",
            "        [0.2135, 0.1866, 0.3154, 0.2845],\n",
            "        [0.2661, 0.3428, 0.1614, 0.2297]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hPBQpki_n6yY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sequential data"
      ]
    },
    {
      "metadata": {
        "id": "kP1awuluoCSr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "There are a variety of different sequential tasks that RNNs can help with.\n",
        "\n",
        "1. **One to one**: there is one input and produces one output. \n",
        "    * Ex. Given a word predict it's class (verb, noun, etc.).\n",
        "2. **One to many**: one input generates many outputs.\n",
        "    * Ex. Given a sentiment (positive, negative, etc.) generate a review.\n",
        "3. **Many to one**: Many inputs are sequentially processed to generate one output.\n",
        "    * Ex. Process the words in a review to predict the sentiment.\n",
        "4. **Many to many**: Many inputs are sequentially processed to generate many outputs.\n",
        "    * Ex. Given a sentence in French, processes the entire sentence and then generate the English translation.\n",
        "    * Ex. Given a sequence of time-series data, predict the probability of an event (risk of disease) at each time step.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/seq1seq.jpeg\" width=700>"
      ]
    },
    {
      "metadata": {
        "id": "tnxUIEMdukYY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Issues with vanilla RNNs"
      ]
    },
    {
      "metadata": {
        "id": "uMx2s93VLUTt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "There are several issues with the vanilla RNN that we've seen so far. \n",
        "\n",
        "1. When we have an input sequence that has many time steps, it becomes difficult for the model to retain information seen earlier as we process more and more of the downstream timesteps. The goals of the model is to retain the useful components in the previously seen time steps but this becomes cumbersome when we have so many time steps to process. \n",
        "\n",
        "2. During backpropagation, the gradient from the loss has to travel all the way back towards the first time step. If our gradient is larger than 1 (${1.01}^{1000} = 20959$) or less than 1 (${0.99}^{1000} = 4.31e-5$) and we have lot's of time steps, this can quickly spiral out of control.\n",
        "\n",
        "To address both these issues, the concept of gating was introduced to RNNs. Gating allows RNNs to control the information flow between each time step to optimize on the task. Selectively allowing information to pass through allows the model to process inputs with many time steps. The most common RNN gated varients are the long short term memory ([LSTM](https://pytorch.org/docs/stable/nn.html#torch.nn.LSTM)) units and gated recurrent units ([GRUs](https://pytorch.org/docs/stable/nn.html#torch.nn.GRU)). You can read more about how these units work [here](http://colah.github.io/posts/2015-08-Understanding-LSTMs/).\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/gates.png\" width=900>"
      ]
    },
    {
      "metadata": {
        "id": "tirko0kwp-9J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GRU in PyTorch\n",
        "gru = nn.GRU(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UZjUhh4VBWxM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ebeef8a6-584d-4b25-9d52-13ad7d1fb4d0"
      },
      "cell_type": "code",
      "source": [
        "# Initialize synthetic input\n",
        "x_in = torch.randn(batch_size, seq_size, embedding_dim)\n",
        "print (x_in.size())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 10, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xJ_SE7AvBfa4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7c9d4573-bbc6-4e07-c62f-1ee1788e486b"
      },
      "cell_type": "code",
      "source": [
        "# Forward pass\n",
        "out, h_n = gru(x_in)\n",
        "print (\"out:\", out.size())\n",
        "print (\"h_n:\", h_n.size())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "out: torch.Size([5, 10, 256])\n",
            "h_n: torch.Size([1, 5, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ij_GA2Rr9BbA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Note**: Choosing whether to use GRU or LSTM really depends on the data and empirical performance. GRUs offer comparable performance with reduce number of parameters while LSTMs are more efficient and may make the difference in performance for your particular task."
      ]
    },
    {
      "metadata": {
        "id": "9agJw4gwK1LC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bidirectional RNNs"
      ]
    },
    {
      "metadata": {
        "id": "Xck0n-KpmXkV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "There have been many advancements with RNNs ([attention](https://www.oreilly.com/ideas/interpretability-via-attentional-and-memory-based-interfaces-using-tensorflow), Quasi RNNs, etc.) that we will cover in later lessons but one of the basic and widely used ones are bidirectional RNNs (Bi-RNNs). The motivation behind bidirectional RNNs is to process an input sequence by both directions. Accounting for context from both sides can aid in performance when the entire input sequence is known at time of inference. A common application of Bi-RNNs is in translation where it's advantageous to look at an entire sentence from both sides when translating to another language (ie. Japanese â†’ English).\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/birnn.png\" width=700>"
      ]
    },
    {
      "metadata": {
        "id": "gSk_5XrvApCd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# BiGRU in PyTorch\n",
        "bi_gru = nn.GRU(input_size=embedding_dim, hidden_size=hidden_dim, \n",
        "                batch_first=True, bidirectional=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fx7-GTptBCtZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ae3ccdf6-73aa-48a9-c2b6-156f1f0bb084"
      },
      "cell_type": "code",
      "source": [
        "# Forward pass\n",
        "out, h_n = bi_gru(x_in)\n",
        "print (\"out:\", out.size()) # collection of all hidden states from the RNN for each time step\n",
        "print (\"h_n:\", h_n.size()) # last hidden state from the RNN"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "out: torch.Size([5, 10, 512])\n",
            "h_n: torch.Size([2, 5, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k5lvJirLBjI6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Notice that the output for each sample at each timestamp has size 512 (double the hidden dim). This is because this includes both the forward and backward directions from the BiRNN. "
      ]
    },
    {
      "metadata": {
        "id": "mJSknbofK2S9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Document classification with RNNs"
      ]
    },
    {
      "metadata": {
        "id": "JgYdEZmHlmft",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's apply RNNs to the document classification task from the [emebddings notebook](https://colab.research.google.com/drive/1yDa5ZTqKVoLl-qRgH-N9xs3pdrDJ0Fb4) where we want to predict an article's category given its title."
      ]
    },
    {
      "metadata": {
        "id": "eIvXqvPQEiDC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Set up"
      ]
    },
    {
      "metadata": {
        "id": "muTcvMynlmAu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from argparse import Namespace\n",
        "import collections\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "00ESjecep-_y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set Numpy and PyTorch seeds\n",
        "def set_seeds(seed, cuda):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if cuda:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        \n",
        "# Creating directories\n",
        "def handle_dirs(dirpath):\n",
        "    if not os.path.exists(dirpath):\n",
        "        os.makedirs(dirpath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m67THDvxEl1e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "65d350e2-2e83-4c70-ebd0-38c71a093b7b"
      },
      "cell_type": "code",
      "source": [
        "# Arguments\n",
        "args = Namespace(\n",
        "    seed=1234,\n",
        "    cuda=False,\n",
        "    shuffle=True,\n",
        "    data_file=\"news.csv\",\n",
        "    split_data_file=\"split_news.csv\",\n",
        "    vectorizer_file=\"vectorizer.json\",\n",
        "    model_state_file=\"model.pth\",\n",
        "    save_dir=\"news\",\n",
        "    reload_from_files=False,\n",
        "    train_size=0.7,\n",
        "    val_size=0.15,\n",
        "    test_size=0.15,\n",
        "    pretrained_embeddings=None,\n",
        "    cutoff=25, # token must appear at least <cutoff> times to be in SequenceVocabulary\n",
        "    num_epochs=5,\n",
        "    early_stopping_criteria=5,\n",
        "    learning_rate=1e-3,\n",
        "    batch_size=64,\n",
        "    embedding_dim=100,\n",
        "    hidden_dim=100,\n",
        "    num_layers=1,\n",
        "    bidirectional=False,\n",
        "    dropout_p=0.1,\n",
        ")\n",
        "\n",
        "# Set seeds\n",
        "set_seeds(seed=args.seed, cuda=args.cuda)\n",
        "\n",
        "# Create save dir\n",
        "handle_dirs(args.save_dir)\n",
        "\n",
        "# Expand filepaths\n",
        "args.vectorizer_file = os.path.join(args.save_dir, args.vectorizer_file)\n",
        "args.model_state_file = os.path.join(args.save_dir, args.model_state_file)\n",
        "print(\"Expanded filepaths: \")\n",
        "print(\"\\t{}\".format(args.vectorizer_file))\n",
        "print(\"\\t{}\".format(args.model_state_file))\n",
        "\n",
        "# Check CUDA\n",
        "if not torch.cuda.is_available():\n",
        "    args.cuda = False\n",
        "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "print(\"Using CUDA: {}\".format(args.cuda))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Expanded filepaths: \n",
            "\tnews/vectorizer.json\n",
            "\tnews/model.pth\n",
            "Using CUDA: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s7T-_kGvExVW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data"
      ]
    },
    {
      "metadata": {
        "id": "XVyK25xOEwjN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "import urllib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M_gclwECEwll",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Upload data from GitHub to notebook's local drive\n",
        "url = \"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/data/news.csv\"\n",
        "response = urllib.request.urlopen(url)\n",
        "html = response.read()\n",
        "with open(args.data_file, 'wb') as fp:\n",
        "    fp.write(html)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V244zOIPEwoP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e00cdb32-5e3d-4e77-cd8f-139456b1b2df"
      },
      "cell_type": "code",
      "source": [
        "# Raw data\n",
        "df = pd.read_csv(args.data_file, header=0)\n",
        "df.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Business</td>\n",
              "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Business</td>\n",
              "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Business</td>\n",
              "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Business</td>\n",
              "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Business</td>\n",
              "      <td>Oil prices soar to all-time record, posing new...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   category                                              title\n",
              "0  Business  Wall St. Bears Claw Back Into the Black (Reuters)\n",
              "1  Business  Carlyle Looks Toward Commercial Aerospace (Reu...\n",
              "2  Business    Oil and Economy Cloud Stocks' Outlook (Reuters)\n",
              "3  Business  Iraq Halts Oil Exports from Main Southern Pipe...\n",
              "4  Business  Oil prices soar to all-time record, posing new..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "ICl2MNK4EwrL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "76bbf59a-0e95-4b20-c2f6-6e4ad9046f66"
      },
      "cell_type": "code",
      "source": [
        "# Split by category\n",
        "by_category = collections.defaultdict(list)\n",
        "for _, row in df.iterrows():\n",
        "    by_category[row.category].append(row.to_dict())\n",
        "for category in by_category:\n",
        "    print (\"{0}: {1}\".format(category, len(by_category[category])))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Business: 30000\n",
            "Sci/Tech: 30000\n",
            "Sports: 30000\n",
            "World: 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "76PwKQHLEww5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create split data\n",
        "final_list = []\n",
        "for _, item_list in sorted(by_category.items()):\n",
        "    if args.shuffle:\n",
        "        np.random.shuffle(item_list)\n",
        "    n = len(item_list)\n",
        "    n_train = int(args.train_size*n)\n",
        "    n_val = int(args.val_size*n)\n",
        "    n_test = int(args.test_size*n)\n",
        "\n",
        "  # Give data point a split attribute\n",
        "    for item in item_list[:n_train]:\n",
        "        item['split'] = 'train'\n",
        "    for item in item_list[n_train:n_train+n_val]:\n",
        "        item['split'] = 'val'\n",
        "    for item in item_list[n_train+n_val:]:\n",
        "        item['split'] = 'test'  \n",
        "\n",
        "    # Add to final list\n",
        "    final_list.extend(item_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CQeS0KHOEwzm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "51ded6c2-7189-45bb-fcaa-e2e41086ffc2"
      },
      "cell_type": "code",
      "source": [
        "# df with split datasets\n",
        "split_df = pd.DataFrame(final_list)\n",
        "split_df[\"split\"].value_counts()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "train    84000\n",
              "test     18000\n",
              "val      18000\n",
              "Name: split, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "pPJDyVusEw3-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    text = ' '.join(word.lower() for word in text.split(\" \"))\n",
        "    text = re.sub(r\"([.,!?])\", r\" \\1 \", text)\n",
        "    text = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", text)\n",
        "    return text\n",
        "    \n",
        "split_df.title = split_df.title.apply(preprocess_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IAetKendEw6b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b9246069-b110-4394-aa8a-c7bbf14b156c"
      },
      "cell_type": "code",
      "source": [
        "# Save to CSV\n",
        "split_df.to_csv(args.split_data_file, index=False)\n",
        "split_df.head()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>split</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Business</td>\n",
              "      <td>train</td>\n",
              "      <td>general electric posts higher rd quarter profit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Business</td>\n",
              "      <td>train</td>\n",
              "      <td>lilly to eliminate up to us jobs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Business</td>\n",
              "      <td>train</td>\n",
              "      <td>s amp p lowers america west outlook to negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Business</td>\n",
              "      <td>train</td>\n",
              "      <td>does rand walk the talk on labor policy ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Business</td>\n",
              "      <td>train</td>\n",
              "      <td>housekeeper advocates for changes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   category  split                                            title\n",
              "0  Business  train  general electric posts higher rd quarter profit\n",
              "1  Business  train                 lilly to eliminate up to us jobs\n",
              "2  Business  train  s amp p lowers america west outlook to negative\n",
              "3  Business  train       does rand walk the talk on labor policy ? \n",
              "4  Business  train                housekeeper advocates for changes"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "NHzGXAI3E7lF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Vocabulary"
      ]
    },
    {
      "metadata": {
        "id": "ZIRUjX0MEw88",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Vocabulary(object):\n",
        "    def __init__(self, token_to_idx=None):\n",
        "\n",
        "        # Token to index\n",
        "        if token_to_idx is None:\n",
        "            token_to_idx = {}\n",
        "        self.token_to_idx = token_to_idx\n",
        "\n",
        "        # Index to token\n",
        "        self.idx_to_token = {idx: token \\\n",
        "                             for token, idx in self.token_to_idx.items()}\n",
        "\n",
        "    def to_serializable(self):\n",
        "        return {'token_to_idx': self.token_to_idx}\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        return cls(**contents)\n",
        "\n",
        "    def add_token(self, token):\n",
        "        if token in self.token_to_idx:\n",
        "            index = self.token_to_idx[token]\n",
        "        else:\n",
        "            index = len(self.token_to_idx)\n",
        "            self.token_to_idx[token] = index\n",
        "            self.idx_to_token[index] = token\n",
        "        return index\n",
        "\n",
        "    def add_tokens(self, tokens):\n",
        "        return [self.add_token[token] for token in tokens]\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        return self.token_to_idx[token]\n",
        "\n",
        "    def lookup_index(self, index):\n",
        "        if index not in self.idx_to_token:\n",
        "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
        "        return self.idx_to_token[index]\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.token_to_idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1LtYf3lpExBb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Vocabulary instance\n",
        "category_vocab = Vocabulary()\n",
        "for index, row in df.iterrows():\n",
        "    category_vocab.add_token(row.category)\n",
        "print (category_vocab) # __str__\n",
        "print (len(category_vocab)) # __len__\n",
        "print (category_vocab.lookup_token(\"Business\"))\n",
        "print (category_vocab.lookup_index(0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z0zkF6CsE_yH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Sequence vocabulary"
      ]
    },
    {
      "metadata": {
        "id": "QtntaISyE_1c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we're going to create our Vocabulary classes for the article's title, which is a sequence of tokens."
      ]
    },
    {
      "metadata": {
        "id": "ovI8QRefEw_p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4W3ZouuTEw1_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SequenceVocabulary(Vocabulary):\n",
        "    def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n",
        "                 mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\n",
        "                 end_seq_token=\"<END>\"):\n",
        "\n",
        "        super(SequenceVocabulary, self).__init__(token_to_idx)\n",
        "\n",
        "        self.mask_token = mask_token\n",
        "        self.unk_token = unk_token\n",
        "        self.begin_seq_token = begin_seq_token\n",
        "        self.end_seq_token = end_seq_token\n",
        "\n",
        "        self.mask_index = self.add_token(self.mask_token)\n",
        "        self.unk_index = self.add_token(self.unk_token)\n",
        "        self.begin_seq_index = self.add_token(self.begin_seq_token)\n",
        "        self.end_seq_index = self.add_token(self.end_seq_token)\n",
        "        \n",
        "        # Index to token\n",
        "        self.idx_to_token = {idx: token \\\n",
        "                             for token, idx in self.token_to_idx.items()}\n",
        "\n",
        "    def to_serializable(self):\n",
        "        contents = super(SequenceVocabulary, self).to_serializable()\n",
        "        contents.update({'unk_token': self.unk_token,\n",
        "                         'mask_token': self.mask_token,\n",
        "                         'begin_seq_token': self.begin_seq_token,\n",
        "                         'end_seq_token': self.end_seq_token})\n",
        "        return contents\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        return self.token_to_idx.get(token, self.unk_index)\n",
        "    \n",
        "    def lookup_index(self, index):\n",
        "        if index not in self.idx_to_token:\n",
        "            raise KeyError(\"the index (%d) is not in the SequenceVocabulary\" % index)\n",
        "        return self.idx_to_token[index]\n",
        "    \n",
        "    def __str__(self):\n",
        "        return \"<SequenceVocabulary(size=%d)>\" % len(self.token_to_idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.token_to_idx)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g5UHjpi3El37",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7b2644e6-a558-4142-eb74-ac3ec5c7c5b3"
      },
      "cell_type": "code",
      "source": [
        "# Get word counts\n",
        "word_counts = Counter()\n",
        "for title in split_df.title:\n",
        "    for token in title.split(\" \"):\n",
        "        if token not in string.punctuation:\n",
        "            word_counts[token] += 1\n",
        "\n",
        "# Create SequenceVocabulary instance\n",
        "title_vocab = SequenceVocabulary()\n",
        "for word, word_count in word_counts.items():\n",
        "    if word_count >= args.cutoff:\n",
        "        title_vocab.add_token(word)\n",
        "print (title_vocab) # __str__\n",
        "print (len(title_vocab)) # __len__\n",
        "print (title_vocab.lookup_token(\"general\"))\n",
        "print (title_vocab.lookup_index(805))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<SequenceVocabulary(size=4400)>\n",
            "4400\n",
            "4\n",
            "measures\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4Dag6H0SFHAG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Vectorizer"
      ]
    },
    {
      "metadata": {
        "id": "VQIfxcUuKwzz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Something new that we introduce in this Vectorizer is calculating the length of our input sequence. We will use this later on to extract the last relevant hidden state for each input sequence."
      ]
    },
    {
      "metadata": {
        "id": "tsNtEnhBEl6s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NewsVectorizer(object):\n",
        "    def __init__(self, title_vocab, category_vocab):\n",
        "        self.title_vocab = title_vocab\n",
        "        self.category_vocab = category_vocab\n",
        "\n",
        "    def vectorize(self, title, title_length=-1):\n",
        "        indices = [self.title_vocab.lookup_token(token) for token in title.split(\" \")]\n",
        "        indices = [self.title_vocab.begin_seq_index] + indices + \\\n",
        "            [self.title_vocab.end_seq_index]\n",
        "        \n",
        "        if title_length < 0:\n",
        "            title_length = len(indices)\n",
        "\n",
        "        vector = np.zeros(title_length, dtype=np.int64)\n",
        "        vector[:len(indices)] = indices\n",
        "        vector[len(indices):] = self.title_vocab.mask_index\n",
        "\n",
        "        return vector, len(indices)\n",
        "    \n",
        "    def unvectorize(self, vector):\n",
        "        tokens = [self.title_vocab.lookup_index(index) for index in vector]\n",
        "        title = \" \".join(token for token in tokens)\n",
        "        return title\n",
        "\n",
        "    @classmethod\n",
        "    def from_dataframe(cls, df, cutoff=25):\n",
        "        \n",
        "        # Create class vocab\n",
        "        category_vocab = Vocabulary()        \n",
        "        for category in sorted(set(df.category)):\n",
        "            category_vocab.add_token(category)\n",
        "\n",
        "        # Get word counts\n",
        "        word_counts = Counter()\n",
        "        for title in df.title:\n",
        "            for token in title.split(\" \"):\n",
        "                word_counts[token] += 1\n",
        "        \n",
        "        # Create title vocab\n",
        "        title_vocab = SequenceVocabulary()\n",
        "        for word, word_count in word_counts.items():\n",
        "            if word_count >= cutoff:\n",
        "                title_vocab.add_token(word)\n",
        "        \n",
        "        return cls(title_vocab, category_vocab)\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        title_vocab = SequenceVocabulary.from_serializable(contents['title_vocab'])\n",
        "        category_vocab = Vocabulary.from_serializable(contents['category_vocab'])\n",
        "        return cls(title_vocab=title_vocab, category_vocab=category_vocab)\n",
        "    \n",
        "    def to_serializable(self):\n",
        "        return {'title_vocab': self.title_vocab.to_serializable(),\n",
        "                'category_vocab': self.category_vocab.to_serializable()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JtRRXU53El9Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d964efed-2860-4030-ae1b-88540d04bf7f"
      },
      "cell_type": "code",
      "source": [
        "# Vectorizer instance\n",
        "vectorizer = NewsVectorizer.from_dataframe(split_df)\n",
        "print (vectorizer.title_vocab)\n",
        "print (vectorizer.category_vocab)\n",
        "vectorized_title, title_length = vectorizer.vectorize(preprocess_text(\n",
        "    \"Roger Federer wins the Wimbledon tennis tournament.\"))\n",
        "print (np.shape(vectorized_title))\n",
        "print (\"title_length:\", title_length)\n",
        "print (vectorized_title)\n",
        "print (vectorizer.unvectorize(vectorized_title))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<SequenceVocabulary(size=4405)>\n",
            "<Vocabulary(size=4)>\n",
            "(11,)\n",
            "title_length: 11\n",
            "[   2    1 4152 1232   25    1 2393 4077   39   31    3]\n",
            "<BEGIN> <UNK> federer wins the <UNK> tennis tournament .  <END>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uk_QvpVfFM0S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ]
    },
    {
      "metadata": {
        "id": "oU7oDdelFMR9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pB7FHmiSFMXA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NewsDataset(Dataset):\n",
        "    def __init__(self, df, vectorizer):\n",
        "        self.df = df\n",
        "        self.vectorizer = vectorizer\n",
        "        \n",
        "        # Max title length\n",
        "        get_length = lambda title: len(title.split(\" \"))\n",
        "        self.max_seq_length = max(map(get_length, df.title)) + 2 # (<BEGIN> + <END>)\n",
        "\n",
        "        # Data splits\n",
        "        self.train_df = self.df[self.df.split=='train']\n",
        "        self.train_size = len(self.train_df)\n",
        "        self.val_df = self.df[self.df.split=='val']\n",
        "        self.val_size = len(self.val_df)\n",
        "        self.test_df = self.df[self.df.split=='test']\n",
        "        self.test_size = len(self.test_df)\n",
        "        self.lookup_dict = {'train': (self.train_df, self.train_size), \n",
        "                            'val': (self.val_df, self.val_size),\n",
        "                            'test': (self.test_df, self.test_size)}\n",
        "        self.set_split('train')\n",
        "\n",
        "        # Class weights (for imbalances)\n",
        "        class_counts = df.category.value_counts().to_dict()\n",
        "        def sort_key(item):\n",
        "            return self.vectorizer.category_vocab.lookup_token(item[0])\n",
        "        sorted_counts = sorted(class_counts.items(), key=sort_key)\n",
        "        frequencies = [count for _, count in sorted_counts]\n",
        "        self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32)\n",
        "\n",
        "    @classmethod\n",
        "    def load_dataset_and_make_vectorizer(cls, split_data_file):\n",
        "        df = pd.read_csv(split_data_file, header=0)\n",
        "        train_df = df[df.split=='train']\n",
        "        return cls(df, NewsVectorizer.from_dataframe(train_df))\n",
        "\n",
        "    @classmethod\n",
        "    def load_dataset_and_load_vectorizer(cls, split_data_file, vectorizer_filepath):\n",
        "        df = pd.read_csv(split_data_file, header=0)\n",
        "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
        "        return cls(df, vectorizer)\n",
        "\n",
        "    def load_vectorizer_only(vectorizer_filepath):\n",
        "        with open(vectorizer_filepath) as fp:\n",
        "            return NewsVectorizer.from_serializable(json.load(fp))\n",
        "\n",
        "    def save_vectorizer(self, vectorizer_filepath):\n",
        "        with open(vectorizer_filepath, \"w\") as fp:\n",
        "            json.dump(self.vectorizer.to_serializable(), fp)\n",
        "\n",
        "    def set_split(self, split=\"train\"):\n",
        "        self.target_split = split\n",
        "        self.target_df, self.target_size = self.lookup_dict[split]\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"<Dataset(split={0}, size={1})\".format(\n",
        "            self.target_split, self.target_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.target_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.target_df.iloc[index]\n",
        "        title_vector, title_length = self.vectorizer.vectorize(row.title, title_length=self.max_seq_length)\n",
        "        category_index = self.vectorizer.category_vocab.lookup_token(row.category)\n",
        "        return {'title': title_vector, 'title_length': title_length, \n",
        "                'category': category_index}\n",
        "\n",
        "    def get_num_batches(self, batch_size):\n",
        "        return len(self) // batch_size\n",
        "\n",
        "    def generate_batches(self, batch_size, shuffle=True, drop_last=True, device=\"cpu\"):\n",
        "        dataloader = DataLoader(dataset=self, batch_size=batch_size, \n",
        "                                shuffle=shuffle, drop_last=drop_last)\n",
        "        for data_dict in dataloader:\n",
        "            out_data_dict = {}\n",
        "            for name, tensor in data_dict.items():\n",
        "                out_data_dict[name] = data_dict[name].to(device)\n",
        "            yield out_data_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_Dpb6ZHJFMeb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "8a310a48-3d4b-44f9-b0ac-d591b20f6c94"
      },
      "cell_type": "code",
      "source": [
        "# Dataset instance\n",
        "dataset = NewsDataset.load_dataset_and_make_vectorizer(args.split_data_file)\n",
        "print (dataset) # __str__\n",
        "input_ = dataset[5] # __getitem__\n",
        "print (input_['title'], input_['title_length'], input_['category'])\n",
        "print (dataset.vectorizer.unvectorize(input_['title']))\n",
        "print (dataset.class_weights)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Dataset(split=train, size=84000)\n",
            "[ 2 32 33 10 34 13  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0] 7 0\n",
            "<BEGIN> software firm to cut jobs <END> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK>\n",
            "tensor([0.0000, 0.0000, 0.0000, 0.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_IUIqtbvFUAG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model"
      ]
    },
    {
      "metadata": {
        "id": "xJV5WlDiFVVz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "input â†’ embedding â†’ RNN â†’ FC "
      ]
    },
    {
      "metadata": {
        "id": "rZCzdZZ9FMhm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wbWO4lZcIdqZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gather_last_relevant_hidden(hiddens, x_lengths):\n",
        "    x_lengths = x_lengths.long().detach().cpu().numpy() - 1\n",
        "    out = []\n",
        "    for batch_index, column_index in enumerate(x_lengths):\n",
        "        out.append(hiddens[batch_index, column_index])\n",
        "    return torch.stack(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9TT66Y-UFMcZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NewsModel(nn.Module):\n",
        "    def __init__(self, embedding_dim, num_embeddings, hidden_dim, output_dim, \n",
        "                 num_layers, bidirectional, dropout_p, \n",
        "                 pretrained_embeddings=None, freeze_embeddings=False, \n",
        "                 padding_idx=0):\n",
        "        super(NewsModel, self).__init__()\n",
        "        \n",
        "        if pretrained_embeddings is None:\n",
        "            self.embeddings = nn.Embedding(embedding_dim=embedding_dim,\n",
        "                                          num_embeddings=num_embeddings,\n",
        "                                          padding_idx=padding_idx)\n",
        "        else:\n",
        "            pretrained_embeddings = torch.from_numpy(pretrained_embeddings).float()\n",
        "            self.embeddings = nn.Embedding(embedding_dim=embedding_dim,\n",
        "                                           num_embeddings=num_embeddings,\n",
        "                                           padding_idx=padding_idx,\n",
        "                                           _weight=pretrained_embeddings)\n",
        "        \n",
        "        # Conv weights\n",
        "        self.gru = nn.GRU(input_size=embedding_dim, hidden_size=hidden_dim, \n",
        "                          num_layers=num_layers, batch_first=True, \n",
        "                          bidirectional=bidirectional)\n",
        "     \n",
        "        # FC weights\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "        if freeze_embeddings:\n",
        "            self.embeddings.weight.requires_grad = False\n",
        "\n",
        "    def forward(self, x_in, x_lengths, apply_softmax=False):\n",
        "        \n",
        "        # Embed\n",
        "        x_in = self.embeddings(x_in)\n",
        "            \n",
        "        # Feed into RNN\n",
        "        out, h_n = self.gru(x_in)\n",
        "        \n",
        "        # Gather the last relevant hidden state\n",
        "        out = gather_last_relevant_hidden(out, x_lengths)\n",
        "\n",
        "        # FC layers\n",
        "        z = self.dropout(out)\n",
        "        z = self.fc1(z)\n",
        "        z = self.dropout(z)\n",
        "        y_pred = self.fc2(z)\n",
        "\n",
        "        if apply_softmax:\n",
        "            y_pred = F.softmax(y_pred, dim=1)\n",
        "        return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jHPYCPd7Fl3M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training"
      ]
    },
    {
      "metadata": {
        "id": "D3seBMA7FlcC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HnRKWLekFlnM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Trainer(object):\n",
        "    def __init__(self, dataset, model, model_state_file, save_dir, device, shuffle, \n",
        "               num_epochs, batch_size, learning_rate, early_stopping_criteria):\n",
        "        self.dataset = dataset\n",
        "        self.class_weights = dataset.class_weights.to(device)\n",
        "        self.model = model.to(device)\n",
        "        self.save_dir = save_dir\n",
        "        self.device = device\n",
        "        self.shuffle = shuffle\n",
        "        self.num_epochs = num_epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.loss_func = nn.CrossEntropyLoss(self.class_weights)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer=self.optimizer, mode='min', factor=0.5, patience=1)\n",
        "        self.train_state = {\n",
        "            'stop_early': False, \n",
        "            'early_stopping_step': 0,\n",
        "            'early_stopping_best_val': 1e8,\n",
        "            'early_stopping_criteria': early_stopping_criteria,\n",
        "            'learning_rate': learning_rate,\n",
        "            'epoch_index': 0,\n",
        "            'train_loss': [],\n",
        "            'train_acc': [],\n",
        "            'val_loss': [],\n",
        "            'val_acc': [],\n",
        "            'test_loss': -1,\n",
        "            'test_acc': -1,\n",
        "            'model_filename': model_state_file}\n",
        "    \n",
        "    def update_train_state(self):\n",
        "\n",
        "        # Verbose\n",
        "        print (\"[EPOCH]: {0} | [LR]: {1} | [TRAIN LOSS]: {2:.2f} | [TRAIN ACC]: {3:.1f}% | [VAL LOSS]: {4:.2f} | [VAL ACC]: {5:.1f}%\".format(\n",
        "          self.train_state['epoch_index'], self.train_state['learning_rate'], \n",
        "            self.train_state['train_loss'][-1], self.train_state['train_acc'][-1], \n",
        "            self.train_state['val_loss'][-1], self.train_state['val_acc'][-1]))\n",
        "\n",
        "        # Save one model at least\n",
        "        if self.train_state['epoch_index'] == 0:\n",
        "            torch.save(self.model.state_dict(), self.train_state['model_filename'])\n",
        "            self.train_state['stop_early'] = False\n",
        "\n",
        "        # Save model if performance improved\n",
        "        elif self.train_state['epoch_index'] >= 1:\n",
        "            loss_tm1, loss_t = self.train_state['val_loss'][-2:]\n",
        "\n",
        "            # If loss worsened\n",
        "            if loss_t >= self.train_state['early_stopping_best_val']:\n",
        "                # Update step\n",
        "                self.train_state['early_stopping_step'] += 1\n",
        "\n",
        "            # Loss decreased\n",
        "            else:\n",
        "                # Save the best model\n",
        "                if loss_t < self.train_state['early_stopping_best_val']:\n",
        "                    torch.save(self.model.state_dict(), self.train_state['model_filename'])\n",
        "\n",
        "                # Reset early stopping step\n",
        "                self.train_state['early_stopping_step'] = 0\n",
        "\n",
        "            # Stop early ?\n",
        "            self.train_state['stop_early'] = self.train_state['early_stopping_step'] \\\n",
        "              >= self.train_state['early_stopping_criteria']\n",
        "        return self.train_state\n",
        "  \n",
        "    def compute_accuracy(self, y_pred, y_target):\n",
        "        _, y_pred_indices = y_pred.max(dim=1)\n",
        "        n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
        "        return n_correct / len(y_pred_indices) * 100\n",
        "  \n",
        "    def run_train_loop(self):\n",
        "        for epoch_index in range(self.num_epochs):\n",
        "            self.train_state['epoch_index'] = epoch_index\n",
        "      \n",
        "            # Iterate over train dataset\n",
        "\n",
        "            # setup: batch generator, set loss and acc to 0, set train mode on\n",
        "            self.dataset.set_split('train')\n",
        "            batch_generator = self.dataset.generate_batches(\n",
        "                batch_size=self.batch_size, shuffle=self.shuffle, \n",
        "                device=self.device)\n",
        "            running_loss = 0.0\n",
        "            running_acc = 0.0\n",
        "            self.model.train()\n",
        "\n",
        "            for batch_index, batch_dict in enumerate(batch_generator):\n",
        "                # the training routine is these 5 steps:\n",
        "\n",
        "                # --------------------------------------\n",
        "                # step 1. zero the gradients\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                # step 2. compute the output\n",
        "                y_pred = self.model(batch_dict['title'], batch_dict['title_length'])\n",
        "\n",
        "                # step 3. compute the loss\n",
        "                loss = self.loss_func(y_pred, batch_dict['category'])\n",
        "                loss_t = loss.item()\n",
        "                running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "                # step 4. use loss to produce gradients\n",
        "                loss.backward()\n",
        "\n",
        "                # step 5. use optimizer to take gradient step\n",
        "                self.optimizer.step()\n",
        "                # -----------------------------------------\n",
        "                # compute the accuracy\n",
        "                acc_t = self.compute_accuracy(y_pred, batch_dict['category'])\n",
        "                running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            self.train_state['train_loss'].append(running_loss)\n",
        "            self.train_state['train_acc'].append(running_acc)\n",
        "\n",
        "            # Iterate over val dataset\n",
        "\n",
        "            # setup: batch generator, set loss and acc to 0; set eval mode on\n",
        "            self.dataset.set_split('val')\n",
        "            batch_generator = self.dataset.generate_batches(\n",
        "                batch_size=self.batch_size, shuffle=self.shuffle, device=self.device)\n",
        "            running_loss = 0.\n",
        "            running_acc = 0.\n",
        "            self.model.eval()\n",
        "\n",
        "            for batch_index, batch_dict in enumerate(batch_generator):\n",
        "\n",
        "                # compute the output\n",
        "                y_pred =  self.model(batch_dict['title'], batch_dict['title_length'])\n",
        "\n",
        "                # step 3. compute the loss\n",
        "                loss = self.loss_func(y_pred, batch_dict['category'])\n",
        "                loss_t = loss.to(\"cpu\").item()\n",
        "                running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "                # compute the accuracy\n",
        "                acc_t = self.compute_accuracy(y_pred, batch_dict['category'])\n",
        "                running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            self.train_state['val_loss'].append(running_loss)\n",
        "            self.train_state['val_acc'].append(running_acc)\n",
        "\n",
        "            self.train_state = self.update_train_state()\n",
        "            self.scheduler.step(self.train_state['val_loss'][-1])\n",
        "            if self.train_state['stop_early']:\n",
        "                break\n",
        "          \n",
        "    def run_test_loop(self):\n",
        "        self.dataset.set_split('test')\n",
        "        batch_generator = self.dataset.generate_batches(\n",
        "            batch_size=self.batch_size, shuffle=self.shuffle, device=self.device)\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        self.model.eval()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # compute the output\n",
        "            y_pred =  self.model(batch_dict['title'], batch_dict['title_length'])\n",
        "\n",
        "            # compute the loss\n",
        "            loss = self.loss_func(y_pred, batch_dict['category'])\n",
        "            loss_t = loss.item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            # compute the accuracy\n",
        "            acc_t = self.compute_accuracy(y_pred, batch_dict['category'])\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "        self.train_state['test_loss'] = running_loss\n",
        "        self.train_state['test_acc'] = running_acc\n",
        "    \n",
        "    def plot_performance(self):\n",
        "        # Figure size\n",
        "        plt.figure(figsize=(15,5))\n",
        "\n",
        "        # Plot Loss\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.title(\"Loss\")\n",
        "        plt.plot(trainer.train_state[\"train_loss\"], label=\"train\")\n",
        "        plt.plot(trainer.train_state[\"val_loss\"], label=\"val\")\n",
        "        plt.legend(loc='upper right')\n",
        "\n",
        "        # Plot Accuracy\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.title(\"Accuracy\")\n",
        "        plt.plot(trainer.train_state[\"train_acc\"], label=\"train\")\n",
        "        plt.plot(trainer.train_state[\"val_acc\"], label=\"val\")\n",
        "        plt.legend(loc='lower right')\n",
        "\n",
        "        # Save figure\n",
        "        plt.savefig(os.path.join(self.save_dir, \"performance.png\"))\n",
        "\n",
        "        # Show plots\n",
        "        plt.show()\n",
        "    \n",
        "    def save_train_state(self):\n",
        "        with open(os.path.join(self.save_dir, \"train_state.json\"), \"w\") as fp:\n",
        "            json.dump(self.train_state, fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ICkiOaGtFlk-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "258439be-1e05-47dd-a1c8-9c753af48be2"
      },
      "cell_type": "code",
      "source": [
        "# Initialization\n",
        "if args.reload_from_files:\n",
        "    print (\"Reloading!\")\n",
        "    dataset = NewsDataset.load_dataset_and_load_vectorizer(\n",
        "        args.split_data_file,args.vectorizer_file)\n",
        "else:\n",
        "    print (\"Creating from scratch!\")\n",
        "    dataset = NewsDataset.load_dataset_and_make_vectorizer(args.split_data_file)\n",
        "    dataset.save_vectorizer(args.vectorizer_file)\n",
        "vectorizer = dataset.vectorizer\n",
        "model = NewsModel(embedding_dim=args.embedding_dim, \n",
        "                  num_embeddings=len(vectorizer.title_vocab), \n",
        "                  hidden_dim=args.hidden_dim,\n",
        "                  output_dim=len(vectorizer.category_vocab),\n",
        "                  num_layers=args.num_layers,\n",
        "                  bidirectional=args.bidirectional,\n",
        "                  dropout_p=args.dropout_p, \n",
        "                  pretrained_embeddings=None, \n",
        "                  padding_idx=vectorizer.title_vocab.mask_index)\n",
        "print (model.named_modules)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating from scratch!\n",
            "<bound method Module.named_modules of NewsModel(\n",
            "  (embeddings): Embedding(3407, 100, padding_idx=0)\n",
            "  (gru): GRU(100, 100, batch_first=True)\n",
            "  (dropout): Dropout(p=0.1)\n",
            "  (fc1): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
            ")>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tuaRZ4DiFlh1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "91a4057f-24b2-44b6-95aa-b58c1e5851d5"
      },
      "cell_type": "code",
      "source": [
        "# Train\n",
        "trainer = Trainer(dataset=dataset, model=model, \n",
        "                  model_state_file=args.model_state_file, \n",
        "                  save_dir=args.save_dir, device=args.device,\n",
        "                  shuffle=args.shuffle, num_epochs=args.num_epochs, \n",
        "                  batch_size=args.batch_size, learning_rate=args.learning_rate, \n",
        "                  early_stopping_criteria=args.early_stopping_criteria)\n",
        "trainer.run_train_loop()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[EPOCH]: 0 | [LR]: 0.001 | [TRAIN LOSS]: 0.75 | [TRAIN ACC]: 70.3% | [VAL LOSS]: 0.54 | [VAL ACC]: 80.4%\n",
            "[EPOCH]: 1 | [LR]: 0.001 | [TRAIN LOSS]: 0.48 | [TRAIN ACC]: 82.7% | [VAL LOSS]: 0.49 | [VAL ACC]: 82.2%\n",
            "[EPOCH]: 2 | [LR]: 0.001 | [TRAIN LOSS]: 0.42 | [TRAIN ACC]: 84.8% | [VAL LOSS]: 0.47 | [VAL ACC]: 82.9%\n",
            "[EPOCH]: 3 | [LR]: 0.001 | [TRAIN LOSS]: 0.38 | [TRAIN ACC]: 86.3% | [VAL LOSS]: 0.46 | [VAL ACC]: 83.4%\n",
            "[EPOCH]: 4 | [LR]: 0.001 | [TRAIN LOSS]: 0.34 | [TRAIN ACC]: 87.7% | [VAL LOSS]: 0.48 | [VAL ACC]: 83.3%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mzRJIz88Flfe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "da8ecd88-72ca-470f-87d4-24984821ca4b"
      },
      "cell_type": "code",
      "source": [
        "# Plot performance\n",
        "trainer.plot_performance()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2gAAAE+CAYAAAD4XjP+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\neIj/B4RKmGeJRdHRAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f835f052748>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "4EmFhiX-FMaV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8fd62b27-4058-4f29-a070-5fd2f2eb6368"
      },
      "cell_type": "code",
      "source": [
        "# Test performance\n",
        "trainer.run_test_loop()\n",
        "print(\"Test loss: {0:.2f}\".format(trainer.train_state['test_loss']))\n",
        "print(\"Test Accuracy: {0:.1f}%\".format(trainer.train_state['test_acc']))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.47\n",
            "Test Accuracy: 83.5%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zVU1zakYFMVF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save all results\n",
        "trainer.save_train_state()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qLoKfjSpFw7t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ]
    },
    {
      "metadata": {
        "id": "ANrPcS7Hp_CP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Inference(object):\n",
        "    def __init__(self, model, vectorizer):\n",
        "        self.model = model\n",
        "        self.vectorizer = vectorizer\n",
        "  \n",
        "    def predict_category(self, title):\n",
        "        # Vectorize\n",
        "        vectorized_title, title_length = self.vectorizer.vectorize(title)\n",
        "        vectorized_title = torch.tensor(vectorized_title).unsqueeze(0)\n",
        "        title_length = torch.tensor([title_length]).long()\n",
        "        \n",
        "        # Forward pass\n",
        "        self.model.eval()\n",
        "        y_pred = self.model(x_in=vectorized_title, x_lengths=title_length, \n",
        "                            apply_softmax=True)\n",
        "\n",
        "        # Top category\n",
        "        y_prob, indices = y_pred.max(dim=1)\n",
        "        index = indices.item()\n",
        "\n",
        "        # Predicted category\n",
        "        category = vectorizer.category_vocab.lookup_index(index)\n",
        "        probability = y_prob.item()\n",
        "        return {'category': category, 'probability': probability}\n",
        "    \n",
        "    def predict_top_k(self, title, k):\n",
        "        # Vectorize\n",
        "        vectorized_title, title_length = self.vectorizer.vectorize(title)\n",
        "        vectorized_title = torch.tensor(vectorized_title).unsqueeze(0)\n",
        "        title_length = torch.tensor([title_length]).long()\n",
        "        \n",
        "        # Forward pass\n",
        "        self.model.eval()\n",
        "        y_pred = self.model(x_in=vectorized_title, x_lengths=title_length, \n",
        "                            apply_softmax=True)\n",
        "        \n",
        "        # Top k categories\n",
        "        y_prob, indices = torch.topk(y_pred, k=k)\n",
        "        probabilities = y_prob.detach().numpy()[0]\n",
        "        indices = indices.detach().numpy()[0]\n",
        "\n",
        "        # Results\n",
        "        results = []\n",
        "        for probability, index in zip(probabilities, indices):\n",
        "            category = self.vectorizer.category_vocab.lookup_index(index)\n",
        "            results.append({'category': category, 'probability': probability})\n",
        "\n",
        "        return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W6wr68o2p_Eh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "49c5cfa1-90c1-4680-f949-026799dbeca7"
      },
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "print (\"Reloading!\")\n",
        "dataset = NewsDataset.load_dataset_and_load_vectorizer(\n",
        "    args.split_data_file, args.vectorizer_file)\n",
        "vectorizer = dataset.vectorizer\n",
        "model = NewsModel(embedding_dim=args.embedding_dim, \n",
        "                  num_embeddings=len(vectorizer.title_vocab), \n",
        "                  hidden_dim=args.hidden_dim,\n",
        "                  output_dim=len(vectorizer.category_vocab),\n",
        "                  num_layers=args.num_layers,\n",
        "                  bidirectional=args.bidirectional,\n",
        "                  dropout_p=args.dropout_p, \n",
        "                  pretrained_embeddings=None, \n",
        "                  padding_idx=vectorizer.title_vocab.mask_index)\n",
        "model.load_state_dict(torch.load(args.model_state_file))\n",
        "model = model.to(args.device)\n",
        "print (model.named_modules)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reloading!\n",
            "<bound method Module.named_modules of NewsModel(\n",
            "  (embeddings): Embedding(3407, 100, padding_idx=0)\n",
            "  (gru): GRU(100, 100, batch_first=True)\n",
            "  (dropout): Dropout(p=0.1)\n",
            "  (fc1): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
            ")>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JPKgHxsfN954",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "db84ca4b-a0ad-4ca9-d89f-ea5516913993"
      },
      "cell_type": "code",
      "source": [
        "# Inference\n",
        "inference = Inference(model=model, vectorizer=vectorizer)\n",
        "title = input(\"Enter a title to classify: \")\n",
        "prediction = inference.predict_category(preprocess_text(title))\n",
        "print(\"{} -> {} (p={:0.2f})\".format(title, prediction['category'], \n",
        "                                    prediction['probability']))"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter a title to classify: President Obama signed the petition during the White House dinner.\n",
            "President Obama signed the petition during the White House dinner. -> World (p=0.91)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JRdz4wzuQR4N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "089a0e0c-d017-48b4-f681-728e404319a4"
      },
      "cell_type": "code",
      "source": [
        "# Top-k inference\n",
        "top_k = inference.predict_top_k(preprocess_text(title), k=len(vectorizer.category_vocab))\n",
        "for result in top_k:\n",
        "    print (\"{} -> {} (p={:0.2f})\".format(title, result['category'], \n",
        "                                         result['probability']))"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "President Obama signed the petition during the White House dinner. -> World (p=0.91)\n",
            "President Obama signed the petition during the White House dinner. -> Business (p=0.05)\n",
            "President Obama signed the petition during the White House dinner. -> Sci/Tech (p=0.03)\n",
            "President Obama signed the petition during the White House dinner. -> Sports (p=0.01)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1YHneO3SStOp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TODO"
      ]
    },
    {
      "metadata": {
        "id": "gGHaKTe1SuEk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- QRNN\n",
        "- conditioned RNN task\n",
        "- interpretability with task to see which words were most influential"
      ]
    }
  ]
}