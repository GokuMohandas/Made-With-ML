# Text classification w/ <img src="https://raw.githubusercontent.com/madewithml/images/master/images/tensorflow.png" width="25rem"> TensorFlow

ðŸš€ This project was created using the [ml-app-template](https://github.com/madewithml/ml-app-template) cookiecutter template. Check it out to start creating your own ML applications.

## Set up
```
virtualenv -p python3.6 venv
source venv/bin/activate
pip install -r requirements.txt
```

## Download embeddings
```bash
python text_classification/utils.py
```

## Training
```bash
python text_classification/train.py \
    --data-url https://raw.githubusercontent.com/madewithml/lessons/master/data/news.csv --lower --shuffle --use_glove
```

## Inference
### Scripts
```bash
python text_classification/predict.py \
    --experiment-id 'latest' \
    --text 'The Wimbledon tennis tournament starts next week!'
```

### cURL
```
curl "http://localhost:5000/predict" \
    -X POST -H "Content-Type: application/json" \
    -d '{"experiment_id": "latest",
         "inputs":
            [{
                "text": "The Wimbledon tennis tournament starts next week!"
             },
             {
                "text": "The Canadian President signed in the new federal law."
             }]
        }'
```

### Requests
```python
import json
import requests

headers = {
    'Content-Type': 'application/json',
}

data = '''{"experiment_id": "latest",
           "inputs":
                [{
                    "text": "The Wimbledon tennis tournament starts next week!"
                 },
                 {
                    "text": "The Canadian President signed in the new federal law."
                 }]
           }'''

response = requests.post('http://0.0.0.0:5000/predict',
                         headers=headers, data=data)
results = json.loads(response.text)
print (json.dumps(results, indent=2, sort_keys=False))
```

## Endpoints
```bash
uvicorn text_classification.app:app --host 0.0.0.0 --port 5000 --reload
GOTO: http://localhost:5000/docs
```

## TensorBoard
```bash
tensorboard --logdir experiments
GOTO: http://localhost:6006/
```

## Tests
```bash
pytest
```

## Docker
1. Build image
```bash
docker build -t text-classification:latest -f Dockerfile .
```
2. Run container
```bash
docker run -d -p 5000:5000 -p 6006:6006 --name text-classification text-classification:latest
```

## Directory structure
```
text-classification/
â”œâ”€â”€ datasets/                           - datasets
â”œâ”€â”€ experiments/                        - experiment directories
â”œâ”€â”€ logs/                               - directory of log files
|   â”œâ”€â”€ errors/                           - error log
|   â”œâ”€â”€ info/                             - info log
â”œâ”€â”€ tensorboard/                        - tensorboard logs
â”œâ”€â”€ tests/                              - unit tests
â”œâ”€â”€ text_classification/                - ml scripts
|   â”œâ”€â”€ app.py                            - app endpoints
|   â”œâ”€â”€ config.py                         - configuration
|   â”œâ”€â”€ data.py                           - data processing
|   â”œâ”€â”€ models.py                         - model architectures
|   â”œâ”€â”€ predict.py                        - inference script
|   â”œâ”€â”€ train.py                          - training script
|   â”œâ”€â”€ utils.py                          - load embeddings
â”œâ”€â”€ .dockerignore                       - files to ignore on docker
â”œâ”€â”€ .gitignore                          - files to ignore on git
â”œâ”€â”€ CODE_OF_CONDUCT.md                  - code of conduct
â”œâ”€â”€ CODEOWNERS                          - code owner assignments
â”œâ”€â”€ CONTRIBUTING.md                     - contributing guidelines
â”œâ”€â”€ Dockerfile                          - dockerfile to containerize app
â”œâ”€â”€ LICENSE                             - license description
â”œâ”€â”€ logging.json                        - logger configuration
â”œâ”€â”€ README.md                           - this README
â”œâ”€â”€ requirements.txt                    - requirements
```

## Overfit to small subset
```
python text_classification/train.py \
    --data-url https://raw.githubusercontent.com/madewithml/lessons/master/data/news.csv --lower --shuffle --data-size 0.1
```

## Experiments
1. Random, unfrozen, embeddings
```
python text_classification/hp.py --exp-cmd "python text_classification/train.py \
    --data-url https://raw.githubusercontent.com/madewithml/lessons/master/data/news.csv --lower --shuffle"
```
2. GloVe, frozen, embeddings
```
python text_classification/hp.py --exp-cmd "python text_classification/train.py \
    --data-url https://raw.githubusercontent.com/madewithml/lessons/master/data/news.csv --lower --shuffle --use-glove --freeze-embeddings"
```
3. GloVe, unfrozen, embeddings
```
python text_classification/hp.py --exp-cmd "python text_classification/train.py \
    --data-url https://raw.githubusercontent.com/madewithml/lessons/master/data/news.csv --lower --shuffle --use-glove"
```

## Helpful docker commands
â€¢Â Build image
```
docker build -t madewithml:latest -f Dockerfile .
```

â€¢ Run container if using `CMD ["python", "app.py"]` or `ENTRYPOINT [ "/bin/sh", "entrypoint.sh"]`
```
docker run -p 5000:5000 --name madewithml madewithml:latest
```

â€¢ Get inside container if using `CMD ["/bin/bash"]`
```
docker run -p 5000:5000 -it madewithml /bin/bash
```

â€¢ Run container with mounted volume
```
docker run -p 5000:5000 -v /Users/goku/Documents/madewithml/:/root/madewithml/ --name madewithml madewithml:latest
```

â€¢ Other flags
```
-d: detached
-ti: interative terminal
```

â€¢ Clean up
```
docker stop $(docker ps -a -q)     # stop all containers
docker rm $(docker ps -a -q)       # remove all containers
docker rmi $(docker images -a -q)  # remove all images
```